{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Hybrid images was proposed in the SIGGRAPH 2006 [paper](https://www.researchgate.net/publication/220184425_Hybrid_images) by Oliva, Torralba, and Schyns. [Here](http://olivalab.mit.edu/hybridimage.htm) is the webpage of their work.\n",
    "\n",
    "Hybrid images are static images that change in interpretation as a function of the viewing distance. The basic idea is that high frequency tends to dominate perception when it is available, but, at a distance, only the low frequency (smooth) part of the signal can be seen. By blending the high frequency portion of one image with the low-frequency portion of another, you get a hybrid image that leads to different interpretations at different distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"hybrid.jpg\" style=\"zoom:100%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low-frequency parts of the image can be understood as \"contours\", such as the shape of the face. \"high attached microdermabrasion\" 微晶磨皮\n",
    "\n",
    "The high-frequency parts of the image can be understood as \"details\", such as wrinkles and spots on the face.\n",
    "\n",
    "Therefore, we often say that the low-frequency part of the image is obtained after the image is blurred, and the image is sharpened to make the high-frequency information of the image more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall idea of the implementation is simple-superimpose a picture with only low-frequency information and an image with only high-frequency information. Specific steps are as follows:\n",
    "\n",
    "1. Prepare low-frequency filters (usually Gaussian blur filter).\n",
    "2. Convolution of each dimension of the first image with Gaussian filter.\n",
    "3. Convolution of each dimension of the second image with Gaussian filter, and subtract the filtered image from the original image to obtain the high-frequency image. ! NOTE that the Gaussian filter in this step may have different standard deviation from the above one. You need to try different values to produce satisfatory results.\n",
    "4. Add the two processed images to get a hybrid image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read a pair of images and alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read a pair of images. You can use the the given images for test, but for submission, you have to use your own images. The image pair should be well aligned for satisfatory results. You need to mannualy select two points on each image and calculate the rotation and scaling parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"cat.bmp\" style=\"zoom:60%\" /> <img src=\"dog.bmp\" style=\"zoom:60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the above cat and dog are not aligned. We need to rotate and scale the dog image to align with the cat. We select the centers of the two eyes on the dog image, then we can caculate the rotation angle and the scaling factor.\n",
    "\n",
    "This method exploys two points on each image. You need to think of appropriate steps to do the alignment. The following steps are just one possible way:\n",
    "\n",
    "1. Select two points A1 and A2 on image A for alignement; and selcet two points B1 and B2 on image B;\n",
    "\n",
    "2. Translate image B so that B1 is aligned with A1;\n",
    "\n",
    "3. Rotate image B to make the line B1B2 have the same direction with line A1A2;\n",
    "\n",
    "4. Scale image B, so that the distance between B1 and B2 is equal to the distance between A1 and A2;\n",
    "\n",
    "5. Crop the images to make the two image have the same size.\n",
    "\n",
    "\n",
    "Please write your code below to align your image pair. Note that, you can use OpenCV functions for rotation and scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, the two points on the first image are:\n",
    "p11 = [100, 200]\n",
    "p12 = [200, 200]\n",
    "# and the corresponding two points on the second image are:\n",
    "p21 = [120, 190]\n",
    "p22 = [190, 220]\n",
    "# TODO: write your own code to calculate the rotation and scaling parameter\n",
    "\n",
    "# TODO: apply the rotation and scaling on the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Make Gaussian filters\n",
    "You need to make your own Gaussian filters even the OpenCV has provided you with some easy to use functions as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# out = cv2.GaussianBlur(in, 0, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you make your own Gaussian filter, you have to specify the filter size (usually odd number) and the standard deviation. In OpenCV, if the kernerl size is given but the standard deviation $\\sigma$ is not given, then $\\sigma$ can be determined according to:\n",
    "$$\n",
    "\\sigma = 0.3*((ksize-1)*0.5 - 1) + 0.8\n",
    "$$\n",
    "If the $\\sigma$ is given but the kernel size is not given, then the kernel size can be se to $6\\sigma$ or $8\\sigma$ (usually an odd number), as we have discussed in the lecture that $[-3\\sigma, 3\\sigma]$ of a Gaussian function captures 99.7% of the energy.\n",
    "\n",
    "This [blog](https://www.cnblogs.com/shine-lee/p/9671253.html) gives a detailed discussion on the selection of kernel size and $\\sigma$.\n",
    "\n",
    "Please finish the following function to generate your Gaussian filter:\n",
    "\n",
    "**NOTE!!!! The sum of the kernel weights should be 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeGaussianFilter(size):\n",
    "    f = None\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Padding your images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use zero-padding to keep the filtered image having the same size with the input image. The padding should be half size of your filter kernel. For example, the following figure shows a 3x3 filter and a 5x5 input image. With padding on the top, bottom, left and right with 1 row/column zeros (note, the filter size 3 divided by 2, therefore the padding is 1, 3//2=1), the filtered image has the same size of the input (5x5). If your filter size is, for example 21x21, then the padding should be 10 rows/columns of zeros on each of the 4 boarders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"zero-padding.png\" style=\"zoom:60%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Padding(im, pad):\n",
    "    im_padded = None\n",
    "    return im_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your own code for the 2D convolution function. Use a filter to convolve on an image (RGB image).\n",
    "\n",
    "For just this assignment, you are forbidden from using any Numpy, Scipy, OpenCV, or other preimplemented functions for filtering. You are allowed to use basic matrix operations like np.shape, np.zeros, and np.transpose. This limitation will be lifted in future assignments, but for now, you should use for loops or Numpy vectorization to apply a kernel to each pixel in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convolution2D(im, filter):\n",
    "    result = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Filter your images and make hybrid image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a Gaussian filter to convolve on image A, get the blured image A'. Make another Gaussian filter to convolve on image B, and substract the result from the original B, get the detail image B'. Add A' and B' to get the hybrid image.\n",
    "\n",
    "NOTE! You may have to try different values for the standard deviation in Gaussian filters to get satifactory results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Make Gaussian pyramid to show your hybrid image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Gaussian filter to build up a Gaussian pyramid. The lower level image in the pyramid should exhibit high frequency information (details); while the higher level image in the pyramid should exhibit low frequency information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"hybrid_image_scales.jpg\" style=\"zoom:60%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "0. The origianl authors' project page. http://olivalab.mit.edu/hybridimage.htm\n",
    "1. A Tutorial. https://jeremykun.com/2014/09/29/hybrid-images/\n",
    "2. Chinese blog，matlab code, with alignment。 https://blog.csdn.net/breeze_blows/article/details/102962559\n",
    "3. Matlab code. https://github.com/coldmanck/Image-Filtering-and-Hybrid-Images\n",
    "4. Soton University. http://comp3204.ecs.soton.ac.uk/cw/coursework2.html\n",
    "5. Brown University. http://cs.brown.edu/courses/cs143/2011/ and the project http://cs.brown.edu/courses/cs143/2011/proj1/\n",
    "6. Python implementation with GUI. https://github.com/ReynoldZhao/Hybrid_Images\n",
    "7. George Washington University, student's homework. https://blog.csdn.net/Sengo_GWU/article/details/79336511\n",
    "8. Georgia Institute of Technology, student's homework. https://github.com/all4win/Computer_Vision_Proj1_Image_Filtering_and_Hybrid_Images and https://www.cc.gatech.edu/classes/AY2016/cs4476_fall/results/proj1/html/jwei74/index.html\n",
    "9. 电子科大的学生作业. https://blog.csdn.net/sinat_41942180/article/details/107972994\n",
    "10. 比较详细的中文博客文章，Matlab代码. https://blog.csdn.net/weixin_45901986/article/details/104823057\n",
    "11. 英国南安普顿大学的博士研究生的知乎文章. https://zhuanlan.zhihu.com/p/106619097\n",
    "12. Washington University in St. Louis. Student's project. https://sites.google.com/site/cse559acomputervisionprojects/home/project-1-hybrid-images"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afc7a63a726cc784aa7767cf0d3930f7764ade87c642be91bae9a4d93430bacb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('crowd': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
