{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1EheOIyrkrj28wAdBZVgFEm0_mplKH0Ux",
      "authorship_tag": "ABX9TyP8XOg9jksJ+dZxL80TdOMe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qilin512/OUC-ComputerVision/blob/main/Texton/Textons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Textons\n",
        "\n"
      ],
      "metadata": {
        "id": "2iIpxkLs3KhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "纹理图像是由重复的规则或随机pattern构成的一类特殊图像。纹理描述了物体的材质。纹理基元（texton）是描述纹理的一种有效方式，是纹理图像的bag-of-visual-words模型。本次作业实现2D纹理图像中的LM texton，是[原文](https://people.eecs.berkeley.edu/~malik/papers/LM-3dtexton.pdf)算法的简化。"
      ],
      "metadata": {
        "id": "r26RmwYpccGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 数据集"
      ],
      "metadata": {
        "id": "SfqrZJIyemfQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们使用[Brodatz数据集](https://sipi.usc.edu/database/database.php?volume=textures)的一部分来做实验。该部分数据和本笔记本一起发布，下载使用即可。这些图像都是单通道1024分辨率。在做分类和重构实验中，可以截取512或者256大小的子图像作为训练集和测试集。"
      ],
      "metadata": {
        "id": "WBCf-v4qeoGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 设计Brodatz数据集的Dataset类\n",
        "# 使用1.3.01.tiff至1.3.13.tiff这13个纹理图像作为13个类别\n",
        "# 但是在训练深度学习模型时，每类需要更多的图像，我们从每类中随机裁剪出100张256*256大小的子图像作为训练或者测试使用\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from torchvision.io import read_image\n",
        "import cv2 # 上面的read_image函数无法读取tiff图像\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "class BrodatzDataset(Dataset):\n",
        "    def __init__(self, img_dir, num_per_class=100, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.num_per_class = num_per_class\n",
        "        self.transform = transform\n",
        "        self.img_files = [img_dir + '1.3.' + str(i).zfill(2) + '.tiff' for i in range(1, 14)]\n",
        "        self.labels = []\n",
        "        for img_file in self.img_files:\n",
        "            label = os.path.basename(img_file).split('.')[0][-2:]\n",
        "            self.labels.append(int(label)-1)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.num_per_class * 13\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        label = index / self.num_per_class\n",
        "        # image = read_image(self.img_files[index]).float()\n",
        "        image1024 = cv2.imread(self.img_files[index], -1)#.astype(np.float32)\n",
        "        h, w = image1024.shape\n",
        "        # image1024 = np.expand_dims(image1024, axis=0)\n",
        "        x = random.randint(0, w - 256)\n",
        "        y = random.randint(0, h - 256)\n",
        "        image = image1024[y:y+256, x:x+256]        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)        \n",
        "        return image, label\n",
        "\n",
        "training_dataset = BrodatzDataset(img_dir='./drive/MyDrive/textures/',\n",
        "                  transform=torchvision.transforms.ToTensor())\n",
        "print(training_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKZVN7iZGjep",
        "outputId": "31a70034-d97b-454d-f1b5-b2ed2071705f"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[0.8431, 0.8627, 0.9020,  ..., 0.8706, 0.8471, 0.7647],\n",
            "         [0.8745, 0.8824, 0.8667,  ..., 0.8667, 0.7922, 0.7647],\n",
            "         [0.8863, 0.9059, 0.8902,  ..., 0.8706, 0.8196, 0.7765],\n",
            "         ...,\n",
            "         [0.8235, 0.7216, 0.6980,  ..., 0.5843, 0.6353, 0.6941],\n",
            "         [0.8510, 0.8431, 0.8471,  ..., 0.6549, 0.5882, 0.6863],\n",
            "         [0.8980, 0.8667, 0.8314,  ..., 0.6000, 0.6314, 0.6510]]]), 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Texton"
      ],
      "metadata": {
        "id": "WRc1UqsojUnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LM filter bank\n",
        "\n",
        "著名的牛津大学的VVG组提供了多种filter bank的[Matlab代码](https://www.robots.ox.ac.uk/~vgg/research/texclass/filters.html)。网上有人做了[Python的实现](https://github.com/tonyjo/LM_filter_bank_python)。这份代码有bug，输出结果和Matlab的不一致，我把这个仓库fork了一份，并修正了其中的bug，稍后会给原作者提PR。本次作业请使用我修改后的[Python代码](https://github.com/qilin512/LM_filter_bank_python/blob/master/lm.py)（我只修改了lm.py文件）。\n",
        "\n",
        "输出的F矩阵（3维数组）包含了48个滤波器，每个都是49*49。"
      ],
      "metadata": {
        "id": "lzpU0D873dx7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "LqhBmXjH3Jm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d54ee889-2dc8-43ab-b053-8a709c7c3d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49, 49, 48)\n"
          ]
        }
      ],
      "source": [
        "# 使用我修改后的代码构造filter bank\n",
        "# 可以把相关的代码拷贝过来，或者把该Python文件加入到工程中，作为jupyter笔记本调用的外部程序。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 基于滤波器响应的纹理图像分类"
      ],
      "metadata": {
        "id": "0aKkOCZ9jfFu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用filter bank对图像进行滤波，每个图像产生C个特征图（假设滤波器个数为C）。计算每个特征图的均值和方差，得到元素个数为2C的特征向量。使用KNN算法在特征向量的基础上对图像进行分类。scikit库里有个使用Garbor filters进行纹理分类的[例子](https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_gabor.html)，有一点相似的地方，可以参考。"
      ],
      "metadata": {
        "id": "o4Fwjz99jmYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用特征图的简单统计特征（均值和方差）对图像进行分类"
      ],
      "metadata": {
        "id": "ydLgt9AqkqVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 生成textons\n",
        "\n",
        "使用LM filter bank对纹理图像进行滤波，并生成Texton。具体地，针对一幅纹理图像（比如$H\\times W$大小），使用filter bank进行滤波（滤波器个数为C），得到$H \\times W \\times C$的特征图。每个像素对应一个C维的特征向量。针对这$H \\times W$个特征向量进行K-means聚类，设置聚类类别数K=20。这K个聚类中心即称为该纹理图像的Texton。这种算法是稀疏编码在纹理图像上的应用，对应着bag-of-words模型里的字典。"
      ],
      "metadata": {
        "id": "qD96BGSA7QXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 你的实现代码"
      ],
      "metadata": {
        "id": "-0ud4vEtYerA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 基于texton的纹理分类\n",
        "\n",
        "如果做纹理分类任务，将数据集中的所有纹理图像都进行上述处理，每个图像都产生K个texton。所有图像的texton放在一起，再按距离把相似的texton进行合并（这一步可选），最终得到Q个texton。这样，每个图像的每个像素属于哪个texton是可追溯的，能得到一幅或者一类图像在这Q个textons上的频率分布（直方图）。在推断的时候，给定一幅纹理图像，滤波后，每个像素对应的特征向量和Q个texton计算距离，每个像素都会对应一个texton，从而获得该图像在Q个texton上的分布直方图。将该直方图和训练集中的每类对应的直方图计算卡方距离（$\\chi^2$ distance），即能进行分类。"
      ],
      "metadata": {
        "id": "Py-Y1j49YeBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 分类任务"
      ],
      "metadata": {
        "id": "CSdXJoEkYh9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 基于texton的纹理重建\n",
        "\n",
        "输入：一幅纹理图像、按照上述方法对这幅图像构建的texton字典。\n",
        "\n",
        "目标：利用texton重构该图像。\n",
        "\n",
        "算法：\n",
        "\n",
        "1. 计算滤波器矩阵的伪逆。将F矩阵里的每个滤波器都拉成一个向量，C个滤波器构成一个新的F矩阵（$HW \\times C$），求这个矩阵的伪逆$F^+$。\n",
        "2. 每个texton都与$F^+$相乘，得到每个texton对应的重构patch。根据原图像的每个像素值对应的texton，找到对应的重构patch，将该patch的中心元素作为重构图像的该像素的像素值。"
      ],
      "metadata": {
        "id": "a7X1UviTYj5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 重构任务的代码"
      ],
      "metadata": {
        "id": "zvc6BFDwcWl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 可学习的特征"
      ],
      "metadata": {
        "id": "cUnAoRnmk3qN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "filter bank设计得很巧妙，是学者的脑力贡献，如何运用filter bank提取的丰富特征？我们前面用过统计特征（均值和方差）和texton（聚类pooling）。如果能从数据中学习到参数，岂不是更好？最后让我们借鉴深度学习里的CNN（convolutional neural network）。\n",
        "\n",
        "请设计一个两层的CNN网络，第一个卷积层设置为我们的filter bank：48个卷积核（滤波器），大小为$49 \\times 49$（够大核的）。第二层卷积层的卷积核个数为类别数，大小为$1 \\times 1$。网络的第三层为global average pooling层(GAP层)。最后接softmax输出类别概率。\n",
        "\n",
        "第一层卷积层因为使用设计好的filter bank，所以需要加载现成的参数，相当于预训练的部分模型参数。\n",
        "\n",
        "实验分两部分。第一部分实验freeze第一个卷积层，只学习第二个卷积层。第二部分实验学习网络的全部参数，相当于对filter bank进行微调fine tuning。对比一下两个部分的分类效果，并把第二部分的微调后的第一个卷积层的滤波器保存并可视化出来，看看和学者们设计的滤波器相比有什么变化。"
      ],
      "metadata": {
        "id": "C5nZKOQ5llcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 华为智能基座吗？\n",
        "# import mindspore as torch\n",
        "\n",
        "# 下面这个示例是关于如何修改网络参数以及固定网络参数不更新\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class TextonNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TextonNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, padding=1, bias=False)\n",
        "        self.fc1 = nn.Linear(2, 3)\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.fc1(out)\n",
        "        return out\n",
        "\n",
        "model = TextonNet()\n",
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param} \\n\")\n",
        "\n",
        "# 修改模型的某个参数，参考这个实现加载LM filter bank\n",
        "with torch.no_grad():\n",
        "    # 修改全连接层矩阵里的某个元素的值\n",
        "    model.fc1.weight[0][0] = 99\n",
        "    # 修改卷积层里的两个滤波器为Sobel算子\n",
        "    model.conv1.weight[0][0] = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
        "    model.conv1.weight[1][0] = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param} \\n\")\n"
      ],
      "metadata": {
        "id": "KYBv97K9sTUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 冻结模型参数"
      ],
      "metadata": {
        "id": "cUs-NivGGPrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取模型的参数，有state_dict和parameters（named_parameters)两种方法，\n",
        "# 除了返回类型不同外，更重要的是参数的requires_grad属性的区别。\n",
        "# 尤其是需要把某些参数freeze，使其不在学习过程中更新\n",
        "\n",
        "\n",
        "# 方法1：直接修改参数的\"requires_grad\"值\n",
        "model.fc1.weight.requires_grad = False\n",
        "\n",
        "# 方法2：通过parameters()或named_parameter()函数返回的生成器(generator)来修改\n",
        "for name, param in model.named_parameters():\n",
        "    if name == 'conv1.weight':\n",
        "        param.requires_grad = False\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f'{name}, {param.requires_grad}')\n",
        "print('\\n')\n",
        "\n",
        "# 如何验证修改成功了呢？\n",
        "# 这时需要使用parameters()或者named_parameters()函数提取参数，然后输出其requires_grad属性查看。\n",
        "# 因为模型训练时，是把模型的parameters()传给优化器，而不是state_dict。\n",
        "\n",
        "# 错误的方法：通过state_dict来修改\n",
        "# 这种做法无法在反向传播时冻结参数\n",
        "# state_dict提取的模型参数的requires_grad默认都是False\n",
        "# 比如直接输出fc1.bias的requires_grad属性，结果为False\n",
        "print(\"state_dict['fc1.bias'].requires_grad is \")\n",
        "print(model.state_dict()['fc1.bias'].requires_grad)\n",
        "\n",
        "# 下面的代码，使用state_dict将fc1.bias的requires_grad修改为False，\n",
        "# 通过state_dict的方式再次验证，其值也是False，\n",
        "# 但是通过named_parameters()方法查看其requires_grad属性，结果还是True\n",
        "model.state_dict()['fc1.bias'] = False\n",
        "print(\"state_dict['fc1.bias'].requires_grad is \")\n",
        "print(model.state_dict()['fc1.bias'].requires_grad)\n",
        "for name, param in model.named_parameters():\n",
        "    print(f'{name}, {param.requires_grad}')\n",
        "print('\\n')\n",
        "# PyTorch这样设计是因为考虑到使用state_dict提取模型参数时通常会做一些修改，\n",
        "# 如果这些修改使用了某些影响梯度跟踪的运算，当requires_grad默认是True时会影响该参数的梯度计算。\n",
        "\n",
        "# 网上有人提到用下面这种方法也是错误的。\n",
        "tmp_state_dict = model.state_dict()\n",
        "tmp_state_dict['fc1.bias'].requires_grad = False\n",
        "model.load_state_dict(tmp_state_dict)\n",
        "for name, param in model.named_parameters():\n",
        "    print(f'{name}, {param.requires_grad}')\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2ZfPrUcAwjj",
        "outputId": "8045b8d9-f315-4454-9390-640293937e75"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight, False\n",
            "fc1.weight, False\n",
            "fc1.bias, True\n",
            "\n",
            "\n",
            "state_dict['fc1.bias'].requires_grad is \n",
            "False\n",
            "state_dict['fc1.bias'].requires_grad is \n",
            "False\n",
            "conv1.weight, False\n",
            "fc1.weight, False\n",
            "fc1.bias, True\n",
            "\n",
            "\n",
            "conv1.weight, False\n",
            "fc1.weight, False\n",
            "fc1.bias, True\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "如果微调后的滤波器分类效果更好的话，可否用在重构任务上？重构的效果会不会更好？如果重构效果更好的话，可否用深度网络实现重构任务？"
      ],
      "metadata": {
        "id": "opevVmn6sgb4"
      }
    }
  ]
}